import logging
from google import genai
from google.genai import types
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

# Configurer le logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Clés API intégrées directement dans le script (à remplacer par vos propres clés)
GEMINI_API_KEY = "AIzaSyCLtmc6OEpU8zyXloVeTQ_kr5le18I8q_I"
TELEGRAM_BOT_TOKEN = "7708331542:AAEkSO_E9c6WRZnK0BxO49UXLWOonLD85pM"

# Initialize the Google GenAI client
client = genai.Client(api_key=GEMINI_API_KEY)
model = "gemini-2.0-flash"
generate_content_config = types.GenerateContentConfig(
    temperature=1,
    top_p=0.95,
    top_k=40,
    max_output_tokens=8192,
    response_mime_type="text/plain",
)

# Memory to store conversation history
conversation_memory = {}

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Hello! I'm your friendly bot with memory. How can I assist you today?")
    logger.info(f"Started conversation with user {update.message.from_user.id}")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    user_input = update.message.text
    logger.info(f"Received message from user {user_id}: {user_input}")

    # Retrieve or initialize conversation history for the user
    if user_id not in conversation_memory:
        conversation_memory[user_id] = []

    conversation_memory[user_id].append(types.Content(role="user", parts=[types.Part.from_text(text=user_input)]))

    # Prepare contents for the API call
    contents = conversation_memory[user_id] + [
        types.Content(role="user", parts=[types.Part.from_text(text="INSERT_INPUT_HERE")])
    ]

    # Generate response from the model
    response_text = ""
    for chunk in client.models.generate_content_stream(
        model=model, contents=contents, config=generate_content_config
    ):
        response_text += chunk.text

    # Add model's response to the conversation history
    conversation_memory[user_id].append(types.Content(role="model", parts=[types.Part.from_text(text=response_text)]))

    await update.message.reply_text(response_text)
    logger.info(f"Sent response to user {user_id}: {response_text}")

if __name__ == '__main__':
    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    start_handler = CommandHandler('start', start)
    message_handler = MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)

    application.add_handler(start_handler)
    application.add_handler(message_handler)

    logger.info("Bot is starting...")
    application.run_polling()
    logger.info("Bot is stopping...")
